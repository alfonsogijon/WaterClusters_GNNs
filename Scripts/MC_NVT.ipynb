{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------ \n",
    "# Script to perform a MC simulation of water clusters on the NVT \n",
    "# ensemble. The potential energy is predicted by a GNN previously\n",
    "# trained. \n",
    "#------------------------------------------------------------------ \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from spektral.data import Dataset, DisjointLoader, Graph\n",
    "from spektral.layers import GlobalSumPool, GATConv\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import random\n",
    "import time\n",
    "\n",
    "from mendeleev import H, O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System \n",
    "N = 237             # number of water molecules\n",
    "\n",
    "# Simulation parameters\n",
    "nblocks = 10        # number of blocks for block-averaging\n",
    "nsteps = 100       # number of steps per block\n",
    "temperature = 100   # in Kelvin\n",
    "pmove = 0.3         # percentage of particles to be moved in each MC step\n",
    "dr_max = 0.003            # length of the movement in atomic units (Bohrs)\n",
    "\n",
    "# Constants\n",
    "kb = 3.1668114e-6   # Boltzmann constant in atomic units (Hartree/Kelvin)\n",
    "beta = 1e0 / (kb * temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset_WaterClusters_big/N237-T100/1000.dat    Energy -4.10263458\n",
      "../dataset_WaterClusters_big/N237-T100/1000.dat    Energy -4.10263458\n"
     ]
    }
   ],
   "source": [
    "# Read initial geometry \n",
    "\n",
    "data_dir = \"../dataset_WaterClusters_big/\"\n",
    "file_name = data_dir+\"N\"+str(N)+\"-T100/1000.dat\"\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    # Define an auxiliar dataset with one single graph\n",
    "\n",
    "    def __init__(self, r2_cutoff, **kwargs):\n",
    "\n",
    "        self.r2_cutoff = r2_cutoff\n",
    "        self.geometry_path = file_name\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    # Define data matrices of a graph (x,a,e)\n",
    "\n",
    "    def read(self):\n",
    "            \n",
    "        def make_graph():\n",
    "\n",
    "            # Process the header of the geometry file\n",
    "            geom_path = self.geometry_path\n",
    "            gfile = open(geom_path,'r')\n",
    "            line = gfile.readline()\n",
    "            n_molecules = int(gfile.readline())\n",
    "            line = gfile.readline()\n",
    "            line = gfile.readline()\n",
    "            line = gfile.readline()\n",
    "            columns = line.split()\n",
    "            energy = float(columns[0])\n",
    "            #energy = float(columns[1]) # electron contribution\n",
    "            line = gfile.readline()\n",
    "            line = gfile.readline()            \n",
    "\n",
    "            # Node features (atom type and position [x,y,z])            \n",
    "            n_nodes = 3*n_molecules\n",
    "            num_physical_features = 4\n",
    "            num_abstract_features = 0\n",
    "            num_node_features = num_physical_features + num_abstract_features\n",
    "            x = np.zeros((n_nodes, num_node_features))\n",
    "            pos = np.zeros((n_nodes, 3))\n",
    "            for inode in range(n_nodes):\n",
    "                line = gfile.readline()\n",
    "                columns = line.split()\n",
    "                if (inode%3==0):\n",
    "                    x[inode,0] = O.atomic_number\n",
    "                else:\n",
    "                    x[inode,0] = H.atomic_number\n",
    "                pos[inode,0:] = columns[1:]\n",
    "                x[inode,1:] = pos[inode,0:]\n",
    "            gfile.close()                \n",
    "\n",
    "            # Binary Adjacency matrix (two nodes/atoms are connected if rij2 < r2_cutoff)\n",
    "            a = np.zeros((n_nodes,n_nodes))\n",
    "            n_edges = 0\n",
    "            for iatom in range(3*n_molecules):\n",
    "                for jatom in range(iatom+1,3*n_molecules):\n",
    "                    rij = pos[iatom,0:] - pos[jatom,0:]\n",
    "                    r2 = np.dot(rij,rij)\n",
    "                    if (r2 <= self.r2_cutoff):\n",
    "                        a[iatom,jatom] = 1\n",
    "                        n_edges = n_edges + 1            \n",
    "            a = np.maximum(a, a.T)#.astype(int) # Adjacency matrix is symetric in this case\n",
    "            a = sp.csr_matrix(a)\n",
    "            #a = normalized_adjacency(a, symmetric=True)\n",
    "            \n",
    "            # No edge features in this case\n",
    "                \n",
    "            # Labels\n",
    "            num_labels = 1\n",
    "            self.num_labels = num_labels\n",
    "            y = np.zeros(num_labels,)\n",
    "            y[0,] = energy\n",
    "\n",
    "            print(str(geom_path)+\"    Energy \"+str(y[0,]))\n",
    "\n",
    "            return Graph(x=x, a=a, y=y)\n",
    "\n",
    "        # We must return a list of Graph objects\n",
    "        return [make_graph()]        \n",
    "\n",
    "d_cutoff = 6.0\n",
    "d2_cutoff = d_cutoff * d_cutoff\n",
    "dataset0 = MyDataset( d2_cutoff ) # dataset with initial graph\n",
    "dataset_aux = MyDataset( d2_cutoff ) # auxiliar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Loss: 214.49659729003906\n",
      "Model: \"net_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gat_conv_14 (GATConv)       multiple                  392       \n",
      "                                                                 \n",
      " gat_conv_15 (GATConv)       multiple                  3304      \n",
      "                                                                 \n",
      " global_sum_pool_7 (GlobalSu  multiple                 0         \n",
      " mPool)                                                          \n",
      "                                                                 \n",
      " dense_21 (Dense)            multiple                  7296      \n",
      "                                                                 \n",
      " dense_22 (Dense)            multiple                  16512     \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,633\n",
      "Trainable params: 27,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GNN model\n",
    "\n",
    "# Config \n",
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 1  # Number of training epochs\n",
    "batch_size = 1  # Batch size\n",
    "n_out = 1\n",
    "loader_tr = DisjointLoader(dataset0, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Build the model\n",
    "class Net(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(8,attn_heads=7,dropout_rate=0,activation=\"relu\")\n",
    "        self.conv2 = GATConv(8,attn_heads=7,dropout_rate=0,activation=\"relu\")\n",
    "        self.global_pool = GlobalSumPool()\n",
    "        self.dense1 = Dense(128,activation=\"relu\")\n",
    "        self.dense2 = Dense(128,activation=\"relu\")\n",
    "        self.dense = Dense(n_out)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #x, a, e, i = inputs\n",
    "        x, a, i = inputs\n",
    "        x = self.conv1([x, a])\n",
    "        x = self.conv2([x, a])\n",
    "        output = self.global_pool([x, i])\n",
    "        output = self.dense1(output)\n",
    "        output = self.dense2(output)\n",
    "        output = self.dense(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = Net()\n",
    "optimizer = Adam(learning_rate)\n",
    "loss_fn = MeanAbsoluteError()\n",
    "\n",
    "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
    "def train_step(inputs, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# fit the model one epoch\n",
    "nepoch = 1\n",
    "step = loss = 0\n",
    "loss_train = []\n",
    "for batch in loader_tr:\n",
    "    step += 1\n",
    "    loss += train_step(*batch)\n",
    "    if step == loader_tr.steps_per_epoch:\n",
    "        step = 0\n",
    "        print(str(nepoch)+\" Loss: {}\".format(loss / loader_tr.steps_per_epoch))\n",
    "        loss_train.append(loss / loader_tr.steps_per_epoch)\n",
    "\n",
    "        nepoch = nepoch + 1\n",
    "        \n",
    "        loss = 0\n",
    "\n",
    "# Load pre-trained weights\n",
    "\n",
    "# load model weights\n",
    "model.load_weights('./Models/GATConv_weights.hdf5')\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: -4.099071979522705\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the energy of a new molecular geometry\n",
    "\n",
    "def energy_GNN(inputs):\n",
    "\n",
    "    # Inputs are data matrices of the graph\n",
    "    x, a, e = inputs\n",
    "\n",
    "    # We save the new graph into the auxiliar dataset and define\n",
    "    # a disjoint loader to evaluate model\n",
    "    graph_aux = Graph(x=x,a=a,e=e,y=0)\n",
    "    dataset_aux[0] = graph_aux\n",
    "    loader_aux = DisjointLoader(dataset_aux, epochs=1) \n",
    "    for batch in loader_aux:\n",
    "        input, y = batch\n",
    "        energy_predicted = model(input, training=False)\n",
    "\n",
    "    return float(energy_predicted)\n",
    "\n",
    "# Check the implementation\n",
    "graph0 = dataset0[0]\n",
    "x = graph0.x\n",
    "a = graph0.a\n",
    "e = graph0.e\n",
    "y = graph0.y\n",
    "inputs = [x, a, e]\n",
    "print( \"Predicted: \"+str(energy_GNN(inputs)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decide if a random movement is accepted with Metropolist test\n",
    "\n",
    "exponent_guard = 75.0\n",
    "\n",
    "def metropolis(delta):\n",
    "\n",
    "    # Input: delta is the negative of argument of exponential\n",
    "\n",
    "    if(delta>exponent_guard): # Too high, reject without evaluationg\n",
    "        accept = False\n",
    "    elif(delta<0): # downhill, accept without evaluating\n",
    "        accept = True\n",
    "    else: # Metropolis test\n",
    "        zeta = random.uniform(0,1) # uniform random number in (0,1)\n",
    "        accept = np.exp(-delta) > zeta\n",
    "\n",
    "    return accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute adjacency matrix from the atomic positions\n",
    "\n",
    "def adjacency(position):\n",
    "\n",
    "    nat,ndim = position.shape\n",
    "    nat = int(nat)\n",
    "    nmol = int(nat/3)\n",
    "    \n",
    "    a = np.zeros((nat,nat))\n",
    "\n",
    "    for iatom in range(3*nmol):\n",
    "        for jatom in range(iatom+1,3*nmol):\n",
    "            rij = position[iatom,:] - position[jatom,:]\n",
    "            r2 = np.dot(rij,rij)\n",
    "            if (r2 <= d2_cutoff):\n",
    "                a[iatom,jatom] = 1\n",
    "    a = np.maximum(a, a.T)#.astype(int) # Adjacency matrix is symetric in this case\n",
    "    a = sp.csr_matrix(a)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance ratio: 53.800000000000004\n",
      "Potential average: -4.113358972684158\n",
      "Exe time (seconds): 391.7228436470032\n"
     ]
    }
   ],
   "source": [
    "# MC loop\n",
    "\n",
    "natoms, nfeatures = x.shape\n",
    "atoms_list = list(range(natoms))\n",
    "natoms_move = int(pmove * natoms)\n",
    "\n",
    "# averages per block\n",
    "potential_block = np.zeros(nblocks)\n",
    "\n",
    "# Initial energy\n",
    "graph0 = dataset0[0]\n",
    "x_old = graph0.x\n",
    "a_old = graph0.a\n",
    "e = graph0.e\n",
    "y_old = graph0.y\n",
    "inputs = [x_old, a_old, e]\n",
    "potential_old = energy_GNN(inputs)\n",
    "r_old = x[:,1:4]\n",
    "#print(potential_old)\n",
    "\n",
    "n = 0\n",
    "nmoves = 0\n",
    "potential_total = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for iblock in range(nblocks):\n",
    "\n",
    "    nmoves_iblock = 0\n",
    "    potential_iblock = 0\n",
    "\n",
    "    for istep in range(nsteps):\n",
    "\n",
    "        n=n+1\n",
    "        #if(istep%10==0): print(istep)\n",
    "        #print(istep)\n",
    "\n",
    "        # multi-particle move (30% of particles)\n",
    "\n",
    "        atoms_move_list = random.sample(atoms_list, natoms_move)\n",
    "        \n",
    "        r_new = r_old.copy()\n",
    "        #r_new[atoms_move_list,:] = (1+random.uniform(-1,1)*dr_max)*r_old[atoms_move_list,:] \n",
    "        r_new[atoms_move_list,:] = r_old[atoms_move_list,:] + random.uniform(-1,1)*dr_max\n",
    "        ############### Chequear que nÃºmeros aleatorios son distintos\n",
    "        x_new = x_old.copy()\n",
    "        x_new[atoms_move_list,1:] = r_new[atoms_move_list,:]\n",
    "        #x_new[atoms_move_list,1:] = (1+random.uniform(-1,1)*dr_max)*x_old[atoms_move_list,1:]\n",
    "        a_new = adjacency(r_new)\n",
    "        #a_new = adjacency(x_new[:,1:])\n",
    "        inputs = [x_new, a_new, e]\n",
    "        potential_new = energy_GNN(inputs)\n",
    "        #print(potential_new)\n",
    "\n",
    "        # Accept of reject the movement\n",
    "\n",
    "        delta = (potential_new - potential_old) * beta\n",
    "        if( metropolis(delta) ):\n",
    "            potential_total = potential_total + potential_new\n",
    "            potential_iblock = potential_iblock + potential_new\n",
    "            nmoves = nmoves + 1    \n",
    "            nmoves_iblock = nmoves_iblock + 1    \n",
    "            r_old = r_new.copy()\n",
    "            x_old = x_new.copy()\n",
    "            potential_old = potential_new\n",
    "        #print(accept)\n",
    "\n",
    "    # accumulate block averages\n",
    "    potential_block[iblock] = potential_iblock / nmoves_iblock\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "exe_time = end_time-start_time # in seconds\n",
    "\n",
    "metro_ratio = float(nmoves)/float(n)*100    # should be around 50%\n",
    "potential_avrg = potential_total / float(nmoves)\n",
    "print(\"Acceptance ratio: \"+str(metro_ratio))\n",
    "print(\"Potential average: \"+str(potential_avrg))\n",
    "print(\"Exe time (seconds): \"+str(exe_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.10806401 -4.10981026 -4.11174465 -4.11383096 -4.11418518 -4.1143243\n",
      " -4.1153825  -4.11646233 -4.11588108 -4.11659373]\n",
      "0.002898723178916973\n",
      "\n",
      "Avrg potential (au): -4.113358972684158\n",
      "Sigma: 0.002898723178916973\n",
      "\n",
      "Avrg potential/N (kcal/mol): -10.891202626745834\n",
      "Sigma: 0.0076751340474007545\n"
     ]
    }
   ],
   "source": [
    "# Compute uncertainty with block-averaging\n",
    "print(potential_block)\n",
    "\n",
    "sigma = 0\n",
    "for iblock in range(nblocks):\n",
    "    sigma = sigma + (potential_block[iblock]-potential_avrg)**2\n",
    "sigma = sigma / (nblocks-1)\n",
    "sigma = np.sqrt(sigma)\n",
    "print(sigma)\n",
    "print()\n",
    "\n",
    "print(\"Avrg potential (au): \"+str(potential_avrg))\n",
    "print(\"Sigma: \"+str(sigma))\n",
    "print()\n",
    "au_to_kcalmol = 627.52\n",
    "print(\"Avrg potential/N (kcal/mol): \"+str(potential_avrg*au_to_kcalmol/N))\n",
    "print(\"Sigma: \"+str(sigma*au_to_kcalmol/N))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNs_WaterClusters_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
