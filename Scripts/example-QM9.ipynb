{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 14:49:47.313558: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 14:49:47.444628: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-22 14:49:47.861286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 14:49:47.861327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 14:49:47.861331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 1422.51it/s]\n",
      "2023-03-22 14:49:50.079150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 14:49:50.101685: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-22 14:49:50.101706: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-22 14:49:50.102300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/alfonso/Work/UGR/Calculations/WaterClusters_GNNs/GNNs_WaterClusters_venv/lib/python3.10/site-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'QM9' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n",
      "/home/alfonso/Work/UGR/Calculations/WaterClusters_GNNs/GNNs_WaterClusters_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:371: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 322075.9375\n",
      "Loss: 268535.75\n",
      "Loss: 139446.59375\n",
      "Loss: 37134.2265625\n",
      "Loss: 12001.03125\n",
      "Loss: 9137.591796875\n",
      "Loss: 7629.01220703125\n",
      "Loss: 6794.40625\n",
      "Loss: 5981.59033203125\n",
      "Loss: 4963.18798828125\n",
      "Testing model\n",
      "Done. Test loss: 157991376.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alfonso/Work/UGR/Calculations/WaterClusters_GNNs/GNNs_WaterClusters_venv/lib/python3.10/site-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example shows how to perform regression of molecular properties with the\n",
    "QM9 database, using a simple GNN in disjoint mode.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from spektral.data import DisjointLoader\n",
    "from spektral.datasets import QM9\n",
    "from spektral.layers import ECCConv, GlobalSumPool\n",
    "\n",
    "################################################################################\n",
    "# Config\n",
    "################################################################################\n",
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 10  # Number of training epochs\n",
    "batch_size = 32  # Batch size\n",
    "\n",
    "################################################################################\n",
    "# Load data\n",
    "################################################################################\n",
    "dataset = QM9(amount=1000)  # Set amount=None to train on whole dataset\n",
    "\n",
    "# Parameters\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "S = dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = dataset.n_labels  # Dimension of the target\n",
    "\n",
    "# Train/test split\n",
    "idxs = np.random.permutation(len(dataset))\n",
    "split = int(0.9 * len(dataset))\n",
    "idx_tr, idx_te = np.split(idxs, [split])\n",
    "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
    "\n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=1)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Build model\n",
    "################################################################################\n",
    "class Net(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ECCConv(32, activation=\"relu\")\n",
    "        self.conv2 = ECCConv(32, activation=\"relu\")\n",
    "        self.global_pool = GlobalSumPool()\n",
    "        self.dense = Dense(n_out)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, e, i = inputs\n",
    "        x = self.conv1([x, a, e])\n",
    "        x = self.conv2([x, a, e])\n",
    "        output = self.global_pool([x, i])\n",
    "        output = self.dense(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "model = Net()\n",
    "optimizer = Adam(learning_rate)\n",
    "loss_fn = MeanSquaredError()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Fit model\n",
    "################################################################################\n",
    "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
    "def train_step(inputs, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "step = loss = 0\n",
    "for batch in loader_tr:\n",
    "    step += 1\n",
    "    loss += train_step(*batch)\n",
    "    if step == loader_tr.steps_per_epoch:\n",
    "        step = 0\n",
    "        print(\"Loss: {}\".format(loss / loader_tr.steps_per_epoch))\n",
    "        loss = 0\n",
    "\n",
    "################################################################################\n",
    "# Evaluate model\n",
    "################################################################################\n",
    "print(\"Testing model\")\n",
    "loss = 0\n",
    "for batch in loader_te:\n",
    "    inputs, target = batch\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss += loss_fn(target, predictions)\n",
    "loss /= loader_te.steps_per_epoch\n",
    "print(\"Done. Test loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNs_WaterClusters_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
